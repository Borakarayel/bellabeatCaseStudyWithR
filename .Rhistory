install.packages("tidyverse")
install.packages("dplyr")
library(tidyverse)
library(dplyr)
library(janitor)
library(lubridate)
library(ggpubr)
library(here)
library(skimr)
library(ggrepel)
library(ggplot2)
# Reading CSV files into data frames
daily_activity <- read.csv(file="~/Data Analysis/Projects/bellabeatCaseStudy/bellaBeatProject_/dataFiles/dailyActivity_merged.csv")
hourly_cal <- read.csv(file="~/Data Analysis/Projects/bellabeatCaseStudy/bellaBeatProject_/dataFiles/hourlyCalories_merged.csv")
hourly_steps <- read.csv(file="~/Data Analysis/Projects/bellabeatCaseStudy/bellaBeatProject_/dataFiles/hourlySteps_merged.csv")
min_sleep <- read.csv(file="~/Data Analysis/Projects/bellabeatCaseStudy/bellaBeatProject_/dataFiles/minuteSleep_merged.csv")
View(daily_activity)
View(daily_activity)
# head() Previewing the first few rows of the data frame
# str() Displaying the structure of the data frame, including column names, data types, and sample data
head(daily_activity)
str(daily_activity)
head(hourly_cal)
str(hourly_cal)
head(hourly_steps)
str(hourly_steps)
head(min_sleep)
str(min_sleep)
# Calculating the number of unique IDs in the daily_activity data frame
n_distinct(daily_activity$Id)
n_distinct(hourly_cal$Id)
n_distinct(hourly_steps$Id)
n_distinct(min_sleep$Id)
# Counting the total number of duplicated rows in the daily_activity data frame
sum(duplicated(daily_activity))
sum(duplicated(min_sleep))
sum(duplicated(hourly_steps))
sum(duplicated(hourly_cal))
# Displaying all rows in min_sleep that are duplicates
View(min_sleep[duplicated(min_sleep), ])
# Displaying both the original and duplicated rows in min_sleep
View(min_sleep[duplicated(min_sleep) | duplicated(min_sleep, fromLast = TRUE), ])
# Counting the total number of NA values in the daily_activity data frame
sum(is.na(min_sleep))
# Counting total number of NA values in the data frame
sum(is.na(daily_activity))
sum(is.na(min_sleep))
sum(is.na(hourly_steps))
sum(is.na(hourly_cal))
# Removing duplicate rows and rows with NA values from the daily_activity data frame
daily_activity <- daily_activity %>%
distinct() %>%  # Remove duplicate rows based on all columns
drop_na()       # Remove rows with any NA values
min_sleep <- min_sleep %>%
distinct() %>%
drop_na()
hourly_steps <- hourly_steps %>%
distinct() %>%
drop_na()
hourly_cal <- hourly_cal %>%
distinct() %>%
drop_na()
# Clean column names to ensure consistent formatting: lowercase, underscores, and removal of special characters
daily_activity <- clean_names(daily_activity)
min_sleep <- clean_names(min_sleep)
hourly_steps <- clean_names(hourly_steps)
hourly_cal <- clean_names(hourly_cal)
# Check the column names of the datasets
colnames(daily_activity)
colnames(hourly_cal)
colnames(hourly_steps)
colnames(min_sleep)
# Standardizing date columns across datasets for consistency before analysis and merging.
# In the daily_activity dataset, the "activity_date" column is renamed to "date", and the values are converted to Date format.
daily_activity_date <- daily_activity %>%
rename(date = activity_date) %>%
mutate(date = as_date(date, format = "%m/%d/%Y"))
# Standardizing date columns across datasets for consistency before analysis and merging.
# In the daily_activity dataset, the "activity_date" column is renamed to "date", and the values are converted to Date format.
daily_activity_date <- daily_activity %>%
rename(date = activity_date) %>%
mutate(date = as_date(date, format = "%m/%d/%Y"))
# In the hourly_cal and hourly_steps datasets, the "activity_hour" column is renamed to "date",
# and the values are converted to Datetime format, including time information, with the system's timezone.
hourly_cal_date <- hourly_cal %>%
rename(date = activity_hour) %>%
mutate(date = as_datetime(date, format = "%m/%d/%Y %I:%M:%S %p", tz = Sys.timezone()))
hourly_steps <- hourly_steps %>%
rename(date = activity_hour) %>%
mutate(date =
View(daily_activity)
View(min_sleep)
View(daily_activity)
View(min_sleep)
View(hourly_step2)
View(hourly_cal)
View(daily_activity_sleep)
# Merging the daily_activity and min_sleep datasets using "id" and "date" as primary keys.
daily_activity_sleep <- merge(daily_activity_date, min_sleep_date, by=c("id", "date"))
# Merging the daily_activity and min_sleep datasets using "id" and "date" as primary keys.
daily_activity_sleep <- merge(daily_activity_date, min_sleep_date, by=c("id", "date"))
# Merging the daily_activity and min_sleep datasets using "id" and "date" as primary keys.
daily_activity_sleep <- merge(daily_activity_date, min_sleep_date, by=c("id", "date"))
# In the min_sleep dataset, the "date" column is converted to a Datetime format,
including time information, with the system's timezone.
min_sleep_date <- min_sleep %>%
mutate(date = as_datetime(date, format = "%m/%d/%Y %I:%M:%S %p", tz = Sys.timezone()))
# In the hourly_cal and hourly_steps datasets, the "activity_hour" column is renamed to "date",
# and the values are converted to Datetime format, including time information, with the system's timezone.
hourly_cal_date <- hourly_cal %>%
rename(date = activity_hour) %>%
mutate(date = as_datetime(date, format = "%m/%d/%Y %I:%M:%S %p", tz = Sys.timezone()))
hourly_steps <- hourly_steps %>%
rename(date = activity_hour) %>%
mutate(date = as_datetime(date, format = "%m/%d/%Y %I:%M:%S %p", tz = Sys.timezone()))
# Merging the daily_activity and min_sleep datasets using "id" and "date" as primary keys.
daily_activity_sleep <- merge(daily_activity_date, min_sleep_date, by=c("id", "date"))
# The glimpse() function provides a quick summary of the merged dataset
glimpse(daily_activity_sleep)
#1 = asleep, 2 = restless, 3 = awake
unique(min_sleep$value)
#Calculates mean steps, calories, and sleep per user and sorts by steps.
daily_average <- daily_activity_sleep %>%
group_by(id)%>%
summarise(mean_daily_steps = mean(total_steps),
mean_daily_calories = mean(calories),
mean_daily_sleep = mean(value)) %>%
arrange(desc(mean_daily_steps))
#check the created daily_average data frame with head function
head(daily_average)
#Classifies users based on average daily steps.
user_type_step <- daily_average %>%
mutate(usage = case_when(
mean_daily_steps < 5000 ~ "sedentary",
mean_daily_steps >= 5000 & mean_daily_steps < 7499 ~ "somewhat active",
mean_daily_steps >= 7500 & mean_daily_steps < 9999 ~ "fairly active",
mean_daily_steps >= 10000 ~ "very active",
TRUE ~ "unknown" #catch all conditions
#check the created daily_average data frame with head function
head(daily_average)
#check the created daily_average data frame with head function
head(daily_average)
#Classifies users based on average daily steps.
user_type_step <- daily_average %>%
mutate(usage = case_when(
mean_daily_steps < 5000 ~ "sedentary",
mean_daily_steps >= 5000 & mean_daily_steps < 7499 ~ "somewhat active",
mean_daily_steps >= 7500 & mean_daily_steps < 9999 ~ "fairly active",
mean_daily_steps >= 10000 ~ "very active",
TRUE ~ "unknown" #catch all conditions
))
#check the created user_type_step data frame with head function
head(user_type_step)
# Groups data, calculates counts, percentages, and formats labels.
user_type_percent <- user_type_step %>%
group_by(usage) %>%
summarise(total = n()) %>%
mutate(total_num_user = sum(total)) %>%
group_by(usage ) %>%
summarise(total_percent = total / total_num_user) %>%
mutate(labels = scales::percent(total_percent))
# Converts 'usage' column to a factor with specified levels.
user_type_percent$usage <- factor(user_type_percent$usage ,
levels = c("very active",
"fairly active",
"somewhat active",
"sedentary"))
#Creates a pie chart visualizing the distribution of user types
user_type_percent %>%
ggplot(aes(x="", y=total_percent, fill=usage))+
geom_bar(stat='identity', width = 1, color="white")+
coord_polar("y", start=0)+
theme_minimal()+
theme(axis.title.x= element_blank(),
axis.title.y = element_blank(),
panel.border = element_blank(),
panel.grid = element_blank(),
axis.ticks = element_blank(),
axis.text.x = element_blank(),
plot.title = element_text(hjust = 0.5, size=14, face = "bold"))+
scale_fill_manual(values = c("#FA8072","#F29F7F", "#F1B278", "#F1C58A"))+
geom_text(aes(label = labels),
position = position_stack(vjust = 0.5))+
labs(title="User Type Distribution")
#Creates a pie chart visualizing the distribution of user types
user_type_percent %>%
ggplot(aes(x="", y=total_percent, fill=usage))+
geom_bar(stat='identity', width = 1, color="white")+
coord_polar("y", start=0)+
theme_minimal()+
theme(axis.title.x= element_blank(),
axis.title.y = element_blank(),
panel.border = element_blank(),
panel.grid = element_blank(),
axis.ticks = element_blank(),
axis.text.x = element_blank(),
plot.title = element_text(hjust = 0.5, size=14, face = "bold"))+
scale_fill_manual(values = c("#FA8072","#F29F7F", "#F1B278", "#F1C58A"))+
geom_text(aes(label = labels),
position = position_stack(vjust = 0.5))+
labs(title="User Type Distribution")
# Converts 'usage' column to a factor with specified levels.
user_type_percent$usage <- factor(user_type_percent$usage ,
levels = c("very active",
"fairly active",
"somewhat active",
"sedentary"))
#Creates a pie chart visualizing the distribution of user types
user_type_percent %>%
ggplot(aes(x="", y=total_percent, fill=usage))+
geom_bar(stat='identity', width = 1, color="white")+
coord_polar("y", start=0)+
theme_minimal()+
theme(axis.title.x= element_blank(),
axis.title.y = element_blank(),
panel.border = element_blank(),
panel.grid = element_blank(),
axis.ticks = element_blank(),
axis.text.x = element_blank(),
plot.title = element_text(hjust = 0.5, size=14, face = "bold"))+
scale_fill_manual(values = c("#FA8072","#F29F7F", "#F1B278", "#F1C58A"))+
geom_text(aes(label = labels),
position = position_stack(vjust = 0.5))+
labs(title="User Type Distribution")
clear
gc()
gc()
---
title: "bellaBeatProject"
library(tidyverse)
library(dplyr)
library(janitor)
library(lubridate)
library(ggpubr)
library(here)
library(skimr)
library(ggrepel)
library(ggplot2)
daily_activity <- read.csv(file="~/Data Analysis/Projects/bellabeatCaseStudy/bellaBeatProject_/dataFiles/Fitabase Data 3.12.16-4.11.16/dailyActivity_merged.csv")
daily_activity <- read.csv(file="~/Data Analysis/Projects/bellabeatCaseStudy/bellaBeatProject_/dataFiles/Fitabase Data 3.12.16-4.11.16/dailyActivity_merged.csv")
heartrate <- read.csv(file="~/Data Analysis/Projects/bellabeatCaseStudy/bellaBeatProject_/dataFiles/Fitabase Data 3.12.16-4.11.16/heartrate_seconds_merged.csv")
daily_activity <- read.csv(file="~/Data Analysis/Projects/bellabeatCaseStudy/bellaBeatProject_/dataFiles/dailyActivity_merged.csv")
```
daily_activity <- read.csv(file="~/Data Analysis/Projects/bellabeatCaseStudy/bellaBeatProject_/dataFiles/dailyActivity_merged.csv")
heartrate <- read.csv(file="~/Data Analysis/Projects/bellabeatCaseStudy/bellaBeatProject_/dataFiles/heartrate_seconds_merged.csv")
hourly_cal <- read.csv(file="~/Data Analysis/Projects/bellabeatCaseStudy/bellaBeatProject_/dataFiles/hourlyCalories_merged.csv")
hourly_intens <- read.csv(file="~/Data Analysis/Projects/bellabeatCaseStudy/bellaBeatProject_/dataFiles/hourlyIntensities_merged.csv")
hourly_steps <- read.csv(file="~/Data Analysis/Projects/bellabeatCaseStudy/bellaBeatProject_/dataFiles/hourlySteps_merged.csv")
min_cal<- read.csv(file="~/Data Analysis/Projects/bellabeatCaseStudy/bellaBeatProject_/dataFiles/minuteCaloriesNarrow_merged.csv")
min_intens <- read.csv(file="~/Data Analysis/Projects/bellabeatCaseStudy/bellaBeatProject_/dataFiles/minuteIntensitiesNarrow_merged.csv")
min_met <- read.csv(file="~/Data Analysis/Projects/bellabeatCaseStudy/bellaBeatProject_/dataFiles/minuteMETsNarrow_merged.csv")
min_sleep <- read.csv(file="~/Data Analysis/Projects/bellabeatCaseStudy/bellaBeatProject_/dataFiles/minuteSleep_merged.csv")
min_steps_nar <- read.csv(file="~/Data Analysis/Projects/bellabeatCaseStudy/bellaBeatProject_/dataFiles/minuteStepsNarrow_merged.csv")
weight_log <- read.csv(file="~/Data Analysis/Projects/bellabeatCaseStudy/bellaBeatProject_/dataFiles/weightLogInfo_merged.csv")
---
title: "bellaBeatProject"
Bellabeat knows that analyzing its available consumer data can uncover valuable opportunities for growth. The company has tasked the marketing analytics team with focusing on one of its products and analyzing smart device usage data to gain insights into how customers are currently using their devices. Based on these findings, Bellabeat aims to generate high-level recommendations that will inform the company's marketing strategy, helping to better align its products with consumer behavior and drive future growth. The goal is to leverage this data to refine marketing tactics and enhance customer engagement.
library(tidyverse)
library(dplyr)
library(janitor)
library(lubridate)
library(ggpubr)
library(here)
library(skimr)
library(ggrepel)
library(ggplot2)
install.packages("tidyverse")
install.packages("dplyr")
install.packages("janitor")
install.packages("lubridate")
install.packages("ggpubr")
install.packages("here")
install.packages("skimr")
install.packages("ggrepel")
install.packages("ggplot2")
install.packages("ggplot2")
library(tidyverse)
library(dplyr)
library(janitor)
library(lubridate)
library(ggpubr)
library(here)
library(skimr)
library(ggrepel)
library(ggplot2)
